#!/usr/bin/env python3
"""
Estimate fisheye camera extrinsics for libxcam surround view using four perimeter boards.

Each calibration image is expected to contain multiple rectangular "ring" boards (outer square
with inner square) placed around the vehicle. Board geometry and pose in the vehicle coordinate
system are described in a JSON configuration file. The script detects board corner points,
matches them to their 3D counterparts, and runs OpenCV's fisheye PnP to recover camera pose.

Outputs:
  * extrinsic_camera_*.txt compatible with xcore/calibration_parser.cpp
  * optional JSON report with per-image poses
  * optional annotated images to verify corner detection

Vehicle coordinate convention:
  - +X : vehicle right
  - +Y : vehicle front
  - +Z : vehicle up
Rotations follow roll (X), pitch (Y), yaw (Z) with compose order Rz(yaw)*Ry(pitch)*Rx(roll).
"""

import argparse
import glob
import json
import math
import os
import sys
from dataclasses import dataclass
from typing import Iterable, List, Optional, Sequence, Tuple

import numpy as np

try:
    import cv2
    from cv2 import fisheye as cv_fisheye
except ImportError as exc:  # pragma: no cover - dependency guard
    print("[ERROR] OpenCV with python bindings is required.", file=sys.stderr)
    raise SystemExit(1) from exc


@dataclass
class BoardSpec:
    name: str
    world_points: np.ndarray  # (N, 3)
    roi: Optional[Tuple[int, int, int, int]]  # x, y, w, h in pixels
    expected_points: int


@dataclass
class DetectionParams:
    adaptive_block_size: int
    adaptive_c: float
    binary_threshold: int
    min_quad_area: float


def parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Calibrate fisheye extrinsics using multiple ring boards placed around a vehicle.")
    parser.add_argument("--intrinsic-json", required=True,
                        help="Path to JSON file generated by calibrate_fisheye_intrinsics.py.")
    parser.add_argument("--board-config", required=True,
                        help="JSON description of board poses and corner layout.")
    parser.add_argument("--images", nargs="+", default=[],
                        help="Explicit list of calibration image paths.")
    parser.add_argument("--image-glob", action="append", default=[],
                        help="Glob pattern(s) for calibration images.")
    parser.add_argument("--min-boards-per-frame", type=int, default=2,
                        help="Minimum number of boards that must be detected in one frame to use it (default: 2).")
    parser.add_argument("--adaptive-block-size", type=int, default=51,
                        help="Odd window size for adaptive thresholding (default: 51).")
    parser.add_argument("--adaptive-c", type=float, default=5.0,
                        help="Constant subtracted in adaptive thresholding (default: 5.0).")
    parser.add_argument("--binary-threshold", type=int, default=0,
                        help="If >0 use fixed threshold instead of adaptive (values 1-255).")
    parser.add_argument("--min-quad-area", type=float, default=500.0,
                        help="Minimum quadrilateral area in pixels within ROI (default: 500).")
    parser.add_argument("--output-txt", required=True,
                        help="Destination file path for extrinsic_camera_*.txt output.")
    parser.add_argument("--save-json",
                        help="Optional JSON report with averaged pose and per-image diagnostics.")
    parser.add_argument("--annotated-dir",
                        help="Optional directory to store annotated detection images.")
    return parser.parse_args()


def collect_images(explicit: Iterable[str], patterns: Iterable[str]) -> List[str]:
    paths: List[str] = list(explicit)
    for pattern in patterns:
        paths.extend(glob.glob(pattern))
    return sorted(set(paths))


def load_intrinsics(path: str) -> Tuple[np.ndarray, np.ndarray]:
    with open(path, "r", encoding="utf-8") as fh:
        data = json.load(fh)

    cam_entry = None
    if isinstance(data, dict):
        cams = data.get("cameras")
        if isinstance(cams, dict):
            cam_list = cams.get("camera")
            if isinstance(cam_list, list) and cam_list:
                cam_entry = cam_list[0]
        if cam_entry is None:
            cam_entry = data
    if cam_entry is None:
        raise ValueError("Could not locate camera entry in intrinsic JSON.")

    K = np.eye(3, dtype=np.float64)
    raw_K = cam_entry.get("K")
    if isinstance(raw_K, (list, tuple)) and len(raw_K) >= 9:
        K.flat[:9] = np.asarray(raw_K[:9], dtype=np.float64)
    else:
        fx = cam_entry.get("fx")
        fy = cam_entry.get("fy")
        cx = cam_entry.get("cx")
        cy = cam_entry.get("cy")
        if None in (fx, fy, cx, cy):
            raise ValueError("Intrinsic JSON missing fx/fy/cx/cy or K matrix.")
        K[0, 0] = fx
        K[1, 1] = fy
        K[0, 2] = cx
        K[1, 2] = cy
        K[0, 1] = cam_entry.get("skew", 0.0)

    D = np.asarray(cam_entry.get("D"), dtype=np.float64).reshape(-1, 1)
    if D.size == 0:
        raise ValueError("Intrinsic JSON missing distortion coefficients `D`.")
    return K, D


def euler_to_matrix(roll: float, pitch: float, yaw: float) -> np.ndarray:
    rx = math.radians(roll)
    ry = math.radians(pitch)
    rz = math.radians(yaw)
    sx, cx = math.sin(rx), math.cos(rx)
    sy, cy = math.sin(ry), math.cos(ry)
    sz, cz = math.sin(rz), math.cos(rz)
    rot_x = np.array([[1, 0, 0],
                      [0, cx, -sx],
                      [0, sx, cx]], dtype=np.float64)
    rot_y = np.array([[cy, 0, sy],
                      [0, 1, 0],
                      [-sy, 0, cy]], dtype=np.float64)
    rot_z = np.array([[cz, -sz, 0],
                      [sz, cz, 0],
                      [0, 0, 1]], dtype=np.float64)
    return rot_z @ rot_y @ rot_x


def matrix_to_euler(R: np.ndarray) -> Tuple[float, float, float]:
    r20 = float(np.clip(-R[2, 0], -1.0, 1.0))
    pitch = math.asin(r20)
    if abs(r20) < 0.999999:
        roll = math.atan2(R[2, 1], R[2, 2])
        yaw = math.atan2(R[1, 0], R[0, 0])
    else:
        roll = math.atan2(-R[0, 1], R[1, 1])
        yaw = 0.0
    return math.degrees(roll), math.degrees(pitch), math.degrees(yaw)


def load_board_config(path: str) -> List[BoardSpec]:
    with open(path, "r", encoding="utf-8") as fh:
        data = json.load(fh)
    if not isinstance(data, dict) or "boards" not in data:
        raise ValueError("Board config JSON must contain a top-level `boards` array.")

    boards: List[BoardSpec] = []
    for entry in data["boards"]:
        if not isinstance(entry, dict):
            continue
        name = entry.get("name", f"board_{len(boards)}")
        translation = np.asarray(entry.get("translation", [0.0, 0.0, 0.0]), dtype=np.float64)
        rotation = entry.get("rotation_deg", [0.0, 0.0, 0.0])
        if len(rotation) != 3:
            raise ValueError(f"Board `{name}` rotation_deg must have three elements.")
        R = euler_to_matrix(rotation[0], rotation[1], rotation[2])

        local_points = entry.get("local_points")
        if not isinstance(local_points, list) or len(local_points) == 0:
            raise ValueError(f"Board `{name}` missing `local_points` array.")
        loc_arr = []
        for pt in local_points:
            if not isinstance(pt, (list, tuple)) or len(pt) < 2:
                raise ValueError(f"Board `{name}` local point must have at least 2 values.")
            if len(pt) == 2:
                loc_arr.append([pt[0], pt[1], 0.0])
            else:
                loc_arr.append([pt[0], pt[1], pt[2]])
        loc_mat = np.asarray(loc_arr, dtype=np.float64)
        world_pts = (R @ loc_mat.T).T + translation

        roi = entry.get("roi")
        roi_tuple = None
        if roi is not None:
            if len(roi) != 4:
                raise ValueError(f"Board `{name}` roi must have four integers [x, y, w, h].")
            roi_tuple = tuple(int(v) for v in roi)

        boards.append(BoardSpec(name=name,
                                world_points=world_pts,
                                roi=roi_tuple,
                                expected_points=len(loc_arr)))
    if not boards:
        raise ValueError("Board configuration did not contain any boards.")
    return boards


def order_quadrilateral(points: np.ndarray) -> np.ndarray:
    pts = np.asarray(points, dtype=np.float64)
    if pts.shape != (4, 2):
        raise ValueError("order_quadrilateral expects a (4,2) array.")
    s = pts.sum(axis=1)
    diff = np.diff(pts, axis=1).reshape(-1)
    top_left = pts[np.argmin(s)]
    bottom_right = pts[np.argmax(s)]
    top_right = pts[np.argmin(diff)]
    bottom_left = pts[np.argmax(diff)]
    return np.vstack([top_left, top_right, bottom_right, bottom_left])


def preprocess_roi(gray_roi: np.ndarray, params: DetectionParams) -> np.ndarray:
    blur = cv2.GaussianBlur(gray_roi, (5, 5), 0)
    if params.binary_threshold > 0:
        _, mask = cv2.threshold(
            blur, params.binary_threshold, 255, cv2.THRESH_BINARY_INV)
    else:
        block = params.adaptive_block_size
        if block % 2 == 0:
            block += 1
        if block < 3:
            block = 3
        mask = cv2.adaptiveThreshold(
            blur, 255,
            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
            cv2.THRESH_BINARY_INV,
            block,
            params.adaptive_c)
    return mask


def detect_board_points(
    gray: np.ndarray,
    roi: Optional[Tuple[int, int, int, int]],
    expected_points: int,
    params: DetectionParams
) -> Optional[np.ndarray]:
    height, width = gray.shape[:2]
    if roi is None:
        x, y, w, h = 0, 0, width, height
    else:
        x, y, w, h = roi
    x = max(0, min(width - 1, x))
    y = max(0, min(height - 1, y))
    w = max(1, min(width - x, w))
    h = max(1, min(height - y, h))

    roi_img = gray[y:y + h, x:x + w]
    mask = preprocess_roi(roi_img, params)
    contours, hierarchy = cv2.findContours(mask, cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
    if hierarchy is None or len(contours) == 0:
        return None
    hierarchy = hierarchy[0]

    approx_polys: List[Optional[np.ndarray]] = [None] * len(contours)
    areas: List[float] = [0.0] * len(contours)
    roi_area = float(w * h)
    min_area = max(params.min_quad_area, 0.005 * roi_area)

    for idx, cnt in enumerate(contours):
        peri = cv2.arcLength(cnt, True)
        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)
        if len(approx) != 4:
            continue
        area = abs(cv2.contourArea(cnt))
        if area < min_area:
            continue
        approx_polys[idx] = approx.reshape(-1, 2)
        areas[idx] = area

    candidates: List[Tuple[float, np.ndarray]] = []
    for idx, poly in enumerate(approx_polys):
        if poly is None:
            continue
        parent = hierarchy[idx][3]
        if parent != -1:
            continue  # only outermost contour

        child_idx = hierarchy[idx][2]
        best_child = None
        best_area = 0.0
        while child_idx != -1:
            child_poly = approx_polys[child_idx]
            if child_poly is not None and areas[child_idx] > best_area:
                best_child = child_poly
                best_area = areas[child_idx]
            child_idx = hierarchy[child_idx][0]

        if best_child is None:
            continue

        outer_ordered = order_quadrilateral(poly)
        inner_ordered = order_quadrilateral(best_child)
        combined = np.vstack([outer_ordered, inner_ordered])
        if combined.shape[0] != expected_points:
            continue
        combined[:, 0] += x
        combined[:, 1] += y
        candidates.append((areas[idx], combined))

    if not candidates:
        return None

    candidates.sort(key=lambda item: item[0], reverse=True)
    return candidates[0][1]


def average_rotation(rotations: Sequence[np.ndarray]) -> np.ndarray:
    accum = np.zeros((3, 3), dtype=np.float64)
    for R in rotations:
        accum += R
    U, _, Vt = np.linalg.svd(accum)
    R_avg = U @ Vt
    if np.linalg.det(R_avg) < 0:
        U[:, -1] *= -1
        R_avg = U @ Vt
    return R_avg


def ensure_directory(path: Optional[str]) -> Optional[str]:
    if path is None:
        return None
    os.makedirs(path, exist_ok=True)
    return path


def main() -> int:
    args = parse_args()
    images = collect_images(args.images, args.image_glob)
    if not images:
        print("[ERROR] No calibration images provided.", file=sys.stderr)
        return 1

    try:
        K, D = load_intrinsics(args.intrinsic_json)
    except (OSError, ValueError) as exc:
        print(f"[ERROR] Failed to load intrinsics: {exc}", file=sys.stderr)
        return 1

    try:
        boards = load_board_config(args.board_config)
    except (OSError, ValueError) as exc:
        print(f"[ERROR] Failed to load board config: {exc}", file=sys.stderr)
        return 1

    detection_params = DetectionParams(
        adaptive_block_size=args.adaptive_block_size,
        adaptive_c=args.adaptive_c,
        binary_threshold=args.binary_threshold,
        min_quad_area=args.min_quad_area)

    annotated_dir = ensure_directory(args.annotated_dir)

    pose_translations: List[np.ndarray] = []
    pose_rotations: List[np.ndarray] = []
    per_image_results = []

    for path in images:
        color = cv2.imread(path, cv2.IMREAD_COLOR)
        if color is None:
            print(f"[WARN] Cannot read image: {path}")
            continue
        gray = cv2.cvtColor(color, cv2.COLOR_BGR2GRAY)

        image_obj_points = []
        image_img_points = []
        detected_boards = []

        for board in boards:
            pts2d = detect_board_points(gray, board.roi, board.expected_points, detection_params)
            if pts2d is None:
                print(f"[WARN] Board `{board.name}` not detected in {path}")
                continue
            image_obj_points.append(board.world_points)
            image_img_points.append(pts2d)
            detected_boards.append((board.name, pts2d))

        if len(detected_boards) < args.min_boards_per_frame:
            print(f"[WARN] Only {len(detected_boards)} board(s) detected in {path}; skipping frame.")
            continue

        obj_pts = np.vstack(image_obj_points).reshape(1, -1, 3)
        img_pts = np.vstack(image_img_points).reshape(1, -1, 2)

        try:
            ret, rvec, tvec = cv_fisheye.solvePnP(
                obj_pts, img_pts, K, D, flags=cv_fisheye.SOLVEPNP_ITERATIVE)
        except cv2.error as exc:
            print(f"[WARN] solvePnP failed for {path}: {exc}")
            continue

        if not ret:
            print(f"[WARN] solvePnP did not converge for {path}")
            continue

        R_wc, _ = cv2.Rodrigues(rvec)
        R_cw = R_wc.T
        cam_center = -R_cw @ tvec

        pose_rotations.append(R_cw)
        pose_translations.append(cam_center.reshape(-1))

        roll, pitch, yaw = matrix_to_euler(R_cw)
        per_image_results.append({
            "image": path,
            "boards_used": [name for name, _ in detected_boards],
            "num_points": int(img_pts.shape[1]),
            "roll": roll,
            "pitch": pitch,
            "yaw": yaw,
            "trans_x": float(cam_center[0]),
            "trans_y": float(cam_center[1]),
            "trans_z": float(cam_center[2])
        })

        if annotated_dir is not None:
            overlay = color.copy()
            for name, pts in detected_boards:
                for idx, (px, py) in enumerate(pts):
                    cv2.circle(overlay, (int(round(px)), int(round(py))), 4, (0, 255, 0), -1)
                    cv2.putText(overlay, f"{name}:{idx+1}", (int(px) + 2, int(py) - 2),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1, cv2.LINE_AA)
            out_path = os.path.join(annotated_dir, os.path.basename(path))
            cv2.imwrite(out_path, overlay)

    if not pose_rotations:
        print("[ERROR] No valid camera poses were estimated. Check detections and images.", file=sys.stderr)
        return 1

    mean_translation = np.mean(np.stack(pose_translations, axis=0), axis=0)
    mean_rotation = average_rotation(pose_rotations)
    roll, pitch, yaw = matrix_to_euler(mean_rotation)

    out_dir = os.path.dirname(os.path.abspath(args.output_txt))
    if out_dir:
        os.makedirs(out_dir, exist_ok=True)
    with open(args.output_txt, "w", encoding="utf-8") as fh:
        fh.write("# translation (millimetres)\n")
        fh.write(f"{mean_translation[0]:.6f}\n")
        fh.write(f"{mean_translation[1]:.6f}\n")
        fh.write(f"{mean_translation[2]:.6f}\n")
        fh.write("# rotation angles (degrees)\n")
        fh.write(f"{roll:.6f}\n")
        fh.write(f"{pitch:.6f}\n")
        fh.write(f"{yaw:.6f}\n")

    print(f"[INFO] Averaged translation (mm): {mean_translation}")
    print(f"[INFO] Averaged rotation (deg): roll={roll:.3f}, pitch={pitch:.3f}, yaw={yaw:.3f}")
    print(f"[INFO] Extrinsic file saved to: {args.output_txt}")

    if args.save_json:
        report = {
            "translation_mm": {
                "x": float(mean_translation[0]),
                "y": float(mean_translation[1]),
                "z": float(mean_translation[2])
            },
            "rotation_deg": {
                "roll": roll,
                "pitch": pitch,
                "yaw": yaw
            },
            "samples_used": len(pose_rotations),
            "frames": per_image_results
        }
        with open(args.save_json, "w", encoding="utf-8") as fh:
            json.dump(report, fh, indent=2)
        print(f"[INFO] Detailed report written to: {args.save_json}")

    return 0


if __name__ == "__main__":
    sys.exit(main())
